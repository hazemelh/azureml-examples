{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to integrate module: opencensus.ext.logging.trace\n",
      "No module named 'opencensus.ext.logging'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://eastus.api.azureml.ms/history/v1.0/subscriptions/96aede12-2f73-41cb-b983-6d11a904839b/resourceGroups/promptflow/providers/Microsoft.MachineLearningServices/workspaces/promptflow-eastus\n"
     ]
    }
   ],
   "source": [
    "import mlflow\n",
    "import requests\n",
    "import json\n",
    "import time\n",
    "from azure.ai.ml import MLClient\n",
    "from azure.identity import DefaultAzureCredential, AzureCliCredential, InteractiveBrowserCredential\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "\n",
    "from mlflow.tracking import MlflowClient\n",
    "from mlflow.utils.rest_utils import http_request\n",
    "import uuid\n",
    "\n",
    "subscription_id = '96aede12-2f73-41cb-b983-6d11a904839b'\n",
    "resource_group = 'promptflow'\n",
    "workspace_name = 'promptflow-eastus'\n",
    "\n",
    "# subscription_id = '96aede12-2f73-41cb-b983-6d11a904839b'\n",
    "# resource_group = 'hod-rg'\n",
    "# workspace_name = 'hod-pflow'\n",
    "\n",
    "ml_client = MLClient(credential=AzureCliCredential(),\n",
    "                        subscription_id=subscription_id,\n",
    "                        resource_group_name=resource_group,\n",
    "                        workspace_name=workspace_name)\n",
    "\n",
    "base_endpoint = ml_client.workspaces.get(ml_client.workspace_name).discovery_url.replace(\"discovery\", \"\")\n",
    "url = (\n",
    "    f\"history/v1.0\"\n",
    "    f\"/subscriptions/{ml_client.subscription_id}\"\n",
    "    f\"/resourceGroups/{ml_client.resource_group_name}\"\n",
    "    f\"/providers/Microsoft.MachineLearningServices\"\n",
    "    f\"/workspaces/{ml_client.workspace_name}\"\n",
    ")\n",
    "endpoint_url = base_endpoint + url\n",
    "print(endpoint_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# credential=AzureCliCredential()\n",
    "credential=InteractiveBrowserCredential()\n",
    "token = credential.get_token(\"https://management.azure.com/.default\").token\n",
    "\n",
    "headers = {  \n",
    "    'Authorization': f'Bearer {token}',\n",
    "    'Content-Type': 'application/json',\n",
    "} "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get run from run history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "run_id = \"c619f648-c809-4545-9f94-f67b0a680706\"    # eastus\n",
    "# run_id = \"web_classification_default_20230809_163800_975156\"    # hod-pflow\n",
    "url = f\"{endpoint_url}/runs/{run_id}\"\n",
    "\n",
    "response = requests.get(url, headers=headers)\n",
    "\n",
    "if response.status_code == 200:\n",
    "    print(f\"Successfully get run from run history\")\n",
    "    with open(\"./download/rh_batch_run.json\", \"w\") as f:\n",
    "        json.dump(response.json(), f, indent=4)\n",
    "else:\n",
    "    print(f\"Code: {response.status_code}, Reason: {response.text}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modify run in run history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyClass:\n",
    "    a = 5\n",
    "\n",
    "# /experimentids/42caf8b8-562b-47f6-b838-0ae2aabb1dc1\n",
    "run_id = \"web_classification_default_20230815_103013_448837\"    # eastus\n",
    "url = f\"{endpoint_url}/runs/{run_id}/modify\"\n",
    "\n",
    "payload = {\n",
    "    # \"runId\": run_id,\n",
    "    \"hidden\": False,\n",
    "    \"tags\": {\n",
    "        \"test_tag\": {\"a\": 123}\n",
    "    },\n",
    "    \"description\": \"\",\n",
    "    \"displayName\": \"hod-run\",\n",
    "}\n",
    "response = requests.patch(url, headers=headers, json=payload)\n",
    "\n",
    "if response.status_code == 200:\n",
    "    print(f\"Successfully updated run.\")\n",
    "    with open(\"./update/rh_batch_run_resp.json\", \"w\") as f:\n",
    "        json.dump(response.json(), f, indent=4)\n",
    "else:\n",
    "    print(f\"Code: {response.status_code}, Reason: {response.text}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get run data from run history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "run_id = \"eval_classification_accuracy_variant_0_20231205_121502_971898\"    # eastus\n",
    "# run_id = \"web_classification_default_20230809_163800_975156\"    # hod-pflow\n",
    "url = f\"{endpoint_url}/rundata\"\n",
    "\n",
    "payload = {\n",
    "    \"runId\": run_id,\n",
    "    \"selectRunMetadata\": True,\n",
    "    \"selectRunDefinition\": True,\n",
    "    \"selectJobSpecification\": True,\n",
    "}\n",
    "\n",
    "response = requests.post(url, headers=headers, json=payload)\n",
    "\n",
    "if response.status_code == 200:\n",
    "    print(f\"Successfully get run from run history\")\n",
    "    with open(\"./download/rh_eval_run_data.json\", \"w\") as f:\n",
    "        json.dump(response.json(), f, indent=4)\n",
    "else:\n",
    "    print(f\"Code: {response.status_code}, Reason: {response.text}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get run from PFS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully get child runs from PFS\n"
     ]
    }
   ],
   "source": [
    "run_id = \"6ce7ef3a-44ed-47c6-abe8-f4e760f67a78\"\n",
    "pfs_endpoint_url = endpoint_url.replace(\"history/v1.0\", \"flow/api\")\n",
    "url = f\"{pfs_endpoint_url}/BulkRuns/{run_id}\"\n",
    "\n",
    "response = requests.get(url, headers=headers)\n",
    "\n",
    "if response.status_code == 200:\n",
    "    print(f\"Successfully get runs from PFS\")\n",
    "    with open(\"./pfs_run_info.json\", \"w\") as f:\n",
    "        json.dump(response.json(), f, indent=4)\n",
    "else:\n",
    "    print(f\"Code: {response.status_code}, Reason: {response.text}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get run from index service"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_id = \"c619f648-c809-4545-9f94-f67b0a680706\"\n",
    "index_endpoint_url = endpoint_url.replace(\"/history\", \"/index\")\n",
    "url = f\"{index_endpoint_url}/entities\"\n",
    "\n",
    "payload = {\n",
    "    \"filters\": [{\n",
    "        \"field\": \"type\",\n",
    "        \"operator\": \"eq\",\n",
    "        \"values\": [\"runs\"]\n",
    "    }, {\n",
    "        \"field\": \"annotations/archived\",\n",
    "        \"operator\": \"eq\",\n",
    "        \"values\": [\"false\"]\n",
    "    },\n",
    "        {\n",
    "            \"field\": \"properties/runId\",\n",
    "            \"operator\": \"eq\",\n",
    "            \"values\": [run_id]\n",
    "        }\n",
    "    ],\n",
    "    \"order\": [{\n",
    "        \"direction\": \"Desc\",\n",
    "        \"field\": \"properties/startTime\"\n",
    "    }\n",
    "    ],\n",
    "    \"pageSize\": 50,\n",
    "}\n",
    "\n",
    "response = requests.post(url, json=payload, headers=headers)\n",
    "\n",
    "if response.status_code == 200:\n",
    "    print(f\"Successfully get run info from index service\")\n",
    "    with open(\"./download/index_batch_run.json\", \"w\") as f:\n",
    "        json.dump(response.json(), f, indent=4)\n",
    "else:\n",
    "    print(f\"Code: {response.status_code}, Reason: {response.text}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### List runs from index service"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_endpoint_url = endpoint_url.replace(\"/history\", \"/index\")\n",
    "url = f\"{index_endpoint_url}/entities\"\n",
    "\n",
    "payload = {\n",
    "    \"filters\": [\n",
    "        {\n",
    "            \"field\": \"type\",\n",
    "            \"operator\": \"eq\",\n",
    "            \"values\": [\"runs\"]\n",
    "        },\n",
    "        {\n",
    "            \"field\": \"annotations/archived\",\n",
    "            \"operator\": \"eq\",\n",
    "            \"values\": [\"false\"]\n",
    "        },\n",
    "        {\n",
    "            \"field\": \"properties/runType\",\n",
    "            \"operator\": \"contains\",\n",
    "            \"values\": [\n",
    "                \"azureml.promptflow.FlowRun\",\n",
    "                \"azureml.promptflow.EvaluationRun\",\n",
    "            ]\n",
    "        }\n",
    "    ],\n",
    "    \"freeTextSearch\": \"\",\n",
    "    \"order\": [\n",
    "        {\n",
    "            \"direction\": \"Desc\",\n",
    "            \"field\": \"properties/creationContext/createdTime\"\n",
    "        }\n",
    "    ],\n",
    "    # index service can return 100 results at most\n",
    "    \"pageSize\": 50,\n",
    "    \"skip\": 0,\n",
    "    \"includeTotalResultCount\": True,\n",
    "    \"searchBuilder\": \"AppendPrefix\"\n",
    "}\n",
    "\n",
    "response = requests.post(url, json=payload, headers=headers)\n",
    "\n",
    "if response.status_code == 200:\n",
    "    print(f\"Successfully listed runs from index service\")\n",
    "    with open(\"./list_entities_50.json\", \"w\") as f:\n",
    "        json.dump(response.json(), f, indent=4)\n",
    "else:\n",
    "    print(f\"Code: {response.status_code}, Reason: {response.text}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get metrics from metric service"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_id = \"groundedness_eval_default_20230821_191944_818788\"\n",
    "index_endpoint_url = endpoint_url.replace(\"/history/v1.0\", \"/metric/v2.0\")\n",
    "url = f\"{index_endpoint_url}/runs/{run_id}/lastvalues\"\n",
    "\n",
    "response = requests.post(url, json={}, headers=headers)\n",
    "\n",
    "if response.status_code == 200:\n",
    "    print(f\"Successfully got metrics from metric service\")\n",
    "    with open(\"./metrics_cle.json\", \"w\") as f:\n",
    "        json.dump(response.json(), f, indent=4)\n",
    "else:\n",
    "    print(f\"Code: {response.status_code}, Reason: {response.text}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### List flows from index service"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_endpoint_url = endpoint_url.replace(\"/history\", \"/index\")\n",
    "url = f\"{index_endpoint_url}/entities\"\n",
    "\n",
    "payload = {\n",
    "    \"filters\": [\n",
    "        {\n",
    "            \"field\": \"type\",\n",
    "            \"operator\": \"eq\",\n",
    "            \"values\": [\"flows\"]\n",
    "        },\n",
    "        # {\n",
    "        #     \"field\": \"annotations/archived\",\n",
    "        #     \"operator\": \"eq\",\n",
    "        #     \"values\": [\"true\"]\n",
    "        # },\n",
    "        {\n",
    "            \"field\": \"properties/creationContext/createdBy/userTenantId\",\n",
    "            \"operator\": \"eq\",\n",
    "            \"values\": [\"72f988bf-86f1-41af-91ab-2d7cd011db47\"]\n",
    "        },\n",
    "        {\n",
    "            \"field\": \"properties/creationContext/createdBy/userObjectId\",\n",
    "            \"operator\": \"eq\",\n",
    "            \"values\": [\"c05e0746-e125-4cb3-9213-a8b535eacd79\"]\n",
    "        }\n",
    "    ],\n",
    "    \"freeTextSearch\": \"\",\n",
    "    \"order\": [\n",
    "        {\n",
    "            \"direction\": \"Desc\",\n",
    "            \"field\": \"properties/creationContext/createdTime\"\n",
    "        }\n",
    "    ],\n",
    "    # index service can return 100 results at most\n",
    "    \"pageSize\": 10,\n",
    "    \"skip\": 0,\n",
    "    \"includeTotalResultCount\": True,\n",
    "    \"searchBuilder\": \"AppendPrefix\"\n",
    "}\n",
    "\n",
    "response = requests.post(url, json=payload, headers=headers)\n",
    "\n",
    "if response.status_code == 200:\n",
    "    print(f\"Successfully listed runs from index service\")\n",
    "    with open(\"./flow_list_archived.json\", \"w\") as f:\n",
    "        json.dump(response.json(), f, indent=4)\n",
    "else:\n",
    "    print(f\"Code: {response.status_code}, Reason: {response.text}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get snapshot sas token from content service"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "snapshot_id = \"194d5c58-3176-4311-88f0-e01a31a5f706\"\n",
    "index_endpoint_url = endpoint_url.replace(\"/history/v1.0\", \"/content/v2.0\")\n",
    "url = f\"{index_endpoint_url}/snapshots/sas\"\n",
    "\n",
    "payload = {\n",
    "    \"snapshotOrAssetId\": snapshot_id,\n",
    "    # \"path\": \"string\"\n",
    "}\n",
    "\n",
    "response = requests.post(url, json=payload, headers=headers)\n",
    "\n",
    "if response.status_code == 200:\n",
    "    print(f\"Successfully got metrics from metric service\")\n",
    "    with open(\"./download/snapshot_sas_resp.json\", \"w\") as f:\n",
    "        json.dump(response.json(), f, indent=4)\n",
    "else:\n",
    "    print(f\"Code: {response.status_code}, Reason: {response.text}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "OUTPUT_PORTAL_PATTERN = re.compile(r\"azureml://.*?/data/(?P<name>.*?)/versions/(?P<version>.*?)$\")\n",
    "target = 'azureml://locations/eastus/workspaces/3e123da1-f9a5-4c91-9234-8d9ffbb39ff5/data/azureml_web_classification_default_20230809_120434_491077_output_data_flow_outputs/versions/1'\n",
    "\n",
    "match = OUTPUT_PORTAL_PATTERN.match(target)\n",
    "if match:\n",
    "    print(match.group('name'))\n",
    "    print(match.group('version'))\n",
    "print(match.groups())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "a = Path(\".\").resolve().absolute()\n",
    "print(str(a))\n",
    "print(a.as_posix())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test promptflow schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from marshmallow_jsonschema import JSONSchema  \n",
    "from promptflow._sdk.schemas._flow_dag import FlowDagSchema\n",
    "\n",
    "json_schema = JSONSchema().dump(FlowDagSchema(context={\"base_path\": \".\"}))\n",
    "with open(\"./flow_dag_schema.json\", \"w\") as f:\n",
    "    json.dump(json_schema, f, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Temprary test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from os import PathLike\n",
    "from pathlib import Path\n",
    "from typing import IO, Any, AnyStr, Dict, List, Optional, Set, Tuple, Union\n",
    "from ruamel.yaml import YAML, YAMLError\n",
    "\n",
    "def load_yaml(source: Optional[Union[AnyStr, PathLike, IO]]) -> Dict:\n",
    "    # null check - just return an empty dict.\n",
    "    # Certain CLI commands rely on this behavior to produce a resource\n",
    "    # via CLI, which is then populated through CLArgs.\n",
    "    \"\"\"Load a local YAML file.\n",
    "\n",
    "    :param source: The relative or absolute path to the local file.\n",
    "    :type source: str\n",
    "    :return: A dictionary representation of the local file's contents.\n",
    "    :rtype: Dict\n",
    "    \"\"\"\n",
    "    # These imports can't be placed in at top file level because it will cause a circular import in\n",
    "    # exceptions.py via _get_mfe_url_override\n",
    "\n",
    "    if source is None:\n",
    "        return {}\n",
    "\n",
    "    # pylint: disable=redefined-builtin\n",
    "    input = None\n",
    "    must_open_file = False\n",
    "    try:  # check source type by duck-typing it as an IOBase\n",
    "        readable = source.readable()\n",
    "        if not readable:  # source is misformatted stream or file\n",
    "            msg = \"File Permissions Error: The already-open \\n\\n inputted file is not readable.\"\n",
    "            raise Exception(msg)\n",
    "        # source is an already-open stream or file, we can read() from it directly.\n",
    "        input = source\n",
    "    except AttributeError:\n",
    "        # source has no writable() function, assume it's a string or file path.\n",
    "        must_open_file = True\n",
    "\n",
    "    if must_open_file:  # If supplied a file path, open it.\n",
    "        try:\n",
    "            input = open(source, \"r\", encoding=\"utf-8\")\n",
    "        except OSError:  # FileNotFoundError introduced in Python 3\n",
    "            msg = \"No such file or directory: {}\"\n",
    "            raise Exception(msg.format(source))\n",
    "    # input should now be a readable file or stream. Parse it.\n",
    "    cfg = {}\n",
    "    try:\n",
    "        yaml = YAML()\n",
    "        yaml.preserve_quotes = True\n",
    "        cfg = yaml.load(input)\n",
    "    except YAMLError as e:\n",
    "        msg = f\"Error while parsing yaml file: {source} \\n\\n {str(e)}\"\n",
    "        raise Exception(msg)\n",
    "    finally:\n",
    "        if must_open_file:\n",
    "            input.close()\n",
    "    return cfg\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "from ruamel.yaml import YAML\n",
    "\n",
    "ryaml = YAML()\n",
    "ryaml.preserve_quotes = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "yaml_file = \"./flows/web_classification/flow.dag.yaml\"\n",
    "\n",
    "with open(yaml_file, encoding=\"utf-8\") as f:\n",
    "    yaml1 = yaml.safe_load(f)\n",
    "\n",
    "with open(yaml_file, encoding=\"utf-8\") as f:\n",
    "    yaml2 = ryaml.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "{'a': [1, 2, 3, 4, True], 'inputs': {'url': {'type': 'string', 'default': 'https://www.microsoft.com/en-us/d/xbox-wireless-controller-stellar-shift-special-edition/94fbjc7h0h6h'}}, 'outputs': {'category': {'type': 'string', 'reference': '${convert_to_dict.output.category}'}, 'evidence': {'type': 'string', 'reference': '${convert_to_dict.output.evidence}'}}, 'nodes': [{'name': 'fetch_text_content_from_url', 'type': 'python', 'source': {'type': 'code', 'path': 'fetch_text_content_from_url.py'}, 'inputs': {'url': '${inputs.url}'}}, {'name': 'summarize_text_content', 'use_variants': True}, {'name': 'prepare_examples', 'type': 'python', 'source': {'type': 'code', 'path': 'prepare_examples.py'}, 'inputs': {}}, {'name': 'classify_with_llm', 'type': 'llm', 'source': {'type': 'code', 'path': 'classify_with_llm.jinja2'}, 'inputs': {'deployment_name': 'text-davinci-003', 'suffix': '', 'max_tokens': '128', 'temperature': '0.2', 'top_p': '1.0', 'logprobs': '', 'echo': 'False', 'stop': '', 'presence_penalty': '0', 'frequency_penalty': '0', 'best_of': '1', 'logit_bias': '', 'url': '${inputs.url}', 'examples': '${prepare_examples.output}', 'text_content': '${summarize_text_content.output}'}, 'provider': 'AzureOpenAI', 'connection': 'open-ai-gogogog', 'api': 'completion', 'module': 'promptflow.tools.aoai'}, {'name': 'convert_to_dict', 'type': 'python', 'source': {'type': 'code', 'path': 'convert_to_dict.py'}, 'inputs': {'input_str': '${classify_with_llm.output}'}}], 'node_variants': {'summarize_text_content': {'default_variant_id': 'variant_1', 'variants': {'variant_0': {'node': {'type': 'llm', 'source': {'type': 'code', 'path': 'summarize_text_content.jinja2'}, 'inputs': {'deployment_name': 'text-davinci-003', 'suffix': '', 'max_tokens': '128', 'temperature': '0.2', 'top_p': '1.0', 'logprobs': '', 'echo': 'False', 'stop': '', 'presence_penalty': '0', 'frequency_penalty': '0', 'best_of': '1', 'logit_bias': '', 'text': '${fetch_text_content_from_url.output}'}, 'provider': 'AzureOpenAI', 'connection': 'open-ai-gogogog', 'api': 'completion', 'module': 'promptflow.tools.aoai'}}, 'variant_1': {'node': {'type': 'llm', 'source': {'type': 'code', 'path': 'summarize_text_content__variant_1.jinja2'}, 'inputs': {'deployment_name': 'text-davinci-003', 'suffix': '', 'max_tokens': '256', 'temperature': '0.2', 'top_p': '1.0', 'logprobs': '', 'echo': 'False', 'stop': '', 'presence_penalty': '0', 'frequency_penalty': '0', 'best_of': '1', 'logit_bias': '', 'text': '${fetch_text_content_from_url.output}'}, 'provider': 'AzureOpenAI', 'connection': 'open-ai-gogogog', 'api': 'completion', 'module': 'promptflow.tools.aoai'}}}}}, 'environment': {'python_requirements_txt': 'requirements.txt'}}\n"
     ]
    }
   ],
   "source": [
    "print(yaml1 == yaml2)\n",
    "print(yaml2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"./yaml1.yaml\", \"w\") as f:\n",
    "    yaml.safe_dump(yaml1, f, indent=4)\n",
    "    \n",
    "ryaml.default_flow_style = True\n",
    "with open(\"./yaml2.yaml\", \"w\") as f:\n",
    "    ryaml.dump(yaml2, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'a': [1, 2, 3, 4, True], 'inputs': {'url': {'type': 'string', 'default': 'https://www.microsoft.com/en-us/d/xbox-wireless-controller-stellar-shift-special-edition/94fbjc7h0h6h'}}, 'outputs': {'category': {'type': 'string', 'reference': '${convert_to_dict.output.category}'}, 'evidence': {'type': 'string', 'reference': '${convert_to_dict.output.evidence}'}}, 'nodes': [{'name': 'fetch_text_content_from_url', 'type': 'python', 'source': {'type': 'code', 'path': 'fetch_text_content_from_url.py'}, 'inputs': {'url': '${inputs.url}'}}, {'name': 'summarize_text_content', 'use_variants': True}, {'name': 'prepare_examples', 'type': 'python', 'source': {'type': 'code', 'path': 'prepare_examples.py'}, 'inputs': {}}, {'name': 'classify_with_llm', 'type': 'llm', 'source': {'type': 'code', 'path': 'classify_with_llm.jinja2'}, 'inputs': {'deployment_name': 'text-davinci-003', 'suffix': '', 'max_tokens': '128', 'temperature': '0.2', 'top_p': '1.0', 'logprobs': '', 'echo': 'False', 'stop': '', 'presence_penalty': '0', 'frequency_penalty': '0', 'best_of': '1', 'logit_bias': '', 'url': '${inputs.url}', 'examples': '${prepare_examples.output}', 'text_content': '${summarize_text_content.output}'}, 'provider': 'AzureOpenAI', 'connection': 'open-ai-gogogog', 'api': 'completion', 'module': 'promptflow.tools.aoai'}, {'name': 'convert_to_dict', 'type': 'python', 'source': {'type': 'code', 'path': 'convert_to_dict.py'}, 'inputs': {'input_str': '${classify_with_llm.output}'}}], 'node_variants': {'summarize_text_content': {'default_variant_id': 'variant_1', 'variants': {'variant_0': {'node': {'type': 'llm', 'source': {'type': 'code', 'path': 'summarize_text_content.jinja2'}, 'inputs': {'deployment_name': 'text-davinci-003', 'suffix': '', 'max_tokens': '128', 'temperature': '0.2', 'top_p': '1.0', 'logprobs': '', 'echo': 'False', 'stop': '', 'presence_penalty': '0', 'frequency_penalty': '0', 'best_of': '1', 'logit_bias': '', 'text': '${fetch_text_content_from_url.output}'}, 'provider': 'AzureOpenAI', 'connection': 'open-ai-gogogog', 'api': 'completion', 'module': 'promptflow.tools.aoai'}}, 'variant_1': {'node': {'type': 'llm', 'source': {'type': 'code', 'path': 'summarize_text_content__variant_1.jinja2'}, 'inputs': {'deployment_name': 'text-davinci-003', 'suffix': '', 'max_tokens': '256', 'temperature': '0.2', 'top_p': '1.0', 'logprobs': '', 'echo': 'False', 'stop': '', 'presence_penalty': '0', 'frequency_penalty': '0', 'best_of': '1', 'logit_bias': '', 'text': '${fetch_text_content_from_url.output}'}, 'provider': 'AzureOpenAI', 'connection': 'open-ai-gogogog', 'api': 'completion', 'module': 'promptflow.tools.aoai'}}}}}, 'environment': {'python_requirements_txt': 'requirements.txt'}}\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "a = Path(yaml_file).read_text()\n",
    "b = ryaml.load(a)\n",
    "print(b)\n",
    "print(b == yaml2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import OrderedDict  \n",
    "  \n",
    "# Create an ordered dictionary  \n",
    "my_dict = OrderedDict()  \n",
    "  \n",
    "# Add key-value pairs to the dictionary  \n",
    "my_dict['apple'] = 3  \n",
    "my_dict['banana'] = 5  \n",
    "my_dict['orange'] = 2  \n",
    "\n",
    "a = {}\n",
    "a[\"a\"] = my_dict\n",
    "a[\"b\"] = [1,2,3,4]\n",
    "a[\"c\"] = \"hello\"\n",
    "\n",
    "# with open(\"./ordered_dict.yaml\", \"w\", encoding=\"utf-8\") as f:\n",
    "#     ryaml.dump(a, f)\n",
    "\n",
    "# with open(\"./ordered_dict_pyyaml.yaml\", \"w\", encoding=\"utf-8\") as f:\n",
    "#     yaml.safe_dump(a, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'a': {'apple': 3, 'banana': 5, 'orange': 2}, 'b': [1, 2, 3, 4], 'c': 'hello'}\n"
     ]
    }
   ],
   "source": [
    "with open(\"./ordered_dict.yaml\", encoding=\"utf-8\") as f:\n",
    "    yaml1 = ryaml.load(f)\n",
    "\n",
    "print(yaml1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"./ordered_dict_1.yaml\", \"w\", encoding=\"utf-8\") as f:\n",
    "    ryaml.dump(a, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'str'> <class 'ruamel.yaml.comments.CommentedMap'>\n",
      "<class 'ruamel.yaml.comments.CommentedMap'>\n",
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "a = load_yaml(yaml_file)\n",
    "with open(yaml_file, encoding=\"utf-8\") as f:\n",
    "    b = load_yaml(f)\n",
    "\n",
    "with open(yaml_file, \"r\", encoding=\"utf-8\") as f:\n",
    "    content = f.read()\n",
    "    # print(content)\n",
    "    c = ryaml.load(content)\n",
    "    print(type(content), type(c))\n",
    "\n",
    "print(type(a))\n",
    "print(a == b)\n",
    "print(a == c)\n",
    "# print(c)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "git_sdk",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "901590fd2121b297931cb9e45033033448ad2d0581b02ead13ed661d40dac950"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
